{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 : Getting to Philosophy \n",
    "\n",
    "Lets play a variation of the [wiki game](https://en.wikipedia.org/wiki/Wikipedia:Wiki_Game) to learn about [this](https://en.wikipedia.org/wiki/Wikipedia:Getting_to_Philosophy) phenomenon. The rules are as follows: \n",
    " - Start using the random article link (wiki menu on the left hand side)\n",
    " - Click on the first non-italicized link outside of parentheses \n",
    " - Ignore external links (e.g., `/wiki/File:...` or `/wiki/Category:...`), links to the current page\n",
    " - Stop when reaching \"Philosophy\", a dead end (page with no links) or when a loop occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Write a function `play` that plays the game and stops if \"Philosophy\" is not reached after `maxiter = 1000` steps. This function should return information to compute the quantities below. \n",
    "\n",
    "Play the game $200$ times. Report \n",
    " - the mean number of sites visited per game, \n",
    " - the maximum number of sites visited per game,\n",
    " - and number of convergences to \"Philosophy\" and \n",
    " - the 20 most visited sites over all 200 games. \n",
    " \n",
    "You may want to use the module `lxml.html` and the function `tostring` `lxml.etree` or similar packages to to parse the html. Besides these, you are allowed to use `requests`, `re`, and `time`. To display the results, you may use `pandas` and its method `pandas.Series.value_counts()` or similar packages. You might find [regexr.com](https://regexr.com/) helpful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint:__ Consider the results below from the function `play`, which takes the wiki-style url as argument and returns a dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__ First, retrieve the `html`. Then, select all text paragraphs (there might be no link in the first one) and parse them back to text. Remove everything inside brackets/ italics in the string using `re`. Then, parse back to `html`. Safely search for the first link. Check if link is valid and points to a new wiki page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html as lx\n",
    "import requests\n",
    "from lxml.etree import tostring\n",
    "import re \n",
    "import time\n",
    "\n",
    "def remove_italics_and_brackets(html_list): \n",
    "    'Removes everything between (...) or <i>...<\\/i>.'\n",
    "    processed_text = ''\n",
    "    for html in html_list: \n",
    "        text = tostring(html).decode('utf-8')\n",
    "        text = re.sub('(<i>.*?<\\/i>)', '', text) #remove italics\n",
    "\n",
    "        # iteratively remove all brackets with no other brackets inside\n",
    "        oldtext = ''\n",
    "        while oldtext != text: \n",
    "            oldtext = text\n",
    "            text = re.sub('(?<=[^_])\\(([^\\(]*?\\))', '', text) \n",
    "        # regex explanation: \n",
    "        # (?<=[^_])     matches only those strings who are not preceded by _, as in a wikilink\n",
    "        #    \\(         matches opening bracket, that... \n",
    "        #      (\n",
    "        #       [^\\(]*? does match an arbitrary number of non-opening bracket characters\n",
    "        #         \\)    and concludes with a closing bracket\n",
    "        #      )   \n",
    "        processed_text += text\n",
    "    return processed_text\n",
    "\n",
    "def first_anchor(html, url): \n",
    "    '''\n",
    "    Returns first link outside of (...) or <i>...<\\/i>, that does \n",
    "    not refer outside of wikipedia or to the same page. \n",
    "    '''\n",
    "    text = remove_italics_and_brackets(html)\n",
    "    html = lx.fromstring(text)\n",
    "    try: # there might be no link at all\n",
    "        links = html.xpath('//a/@href') # these links might not be valid! \n",
    "        for link in links:  \n",
    "            # check if the link goes outside of wikipedia or to, e.g., wiki/File:, ... \n",
    "            # regex explanation: Match everything that is \n",
    "            # (?<!org)      not preceded by org (this would link to wikimedia.org, ect),   \n",
    "            #   \\/wiki\\/     matches /wiki/,\n",
    "            #       (?!.*:)  that is not followed by an arbitrary amount of letters and ':'\n",
    "            if re.search('(?<!org)\\/wiki\\/(?!.*:)', link) is not None:  \n",
    "                # check if link links to same page (then link = url#something)\n",
    "                if url not in link: \n",
    "                    return link\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def get_link(url): \n",
    "    'Fetches first link on wiki page. '\n",
    "    response = requests.get('https://en.wikipedia.org' + url) # in wiki format \n",
    "    response.raise_for_status()\n",
    "    html = lx.fromstring(response.text) # Parse the HTML\n",
    "    try: #this should be all paragraphs, if existing\n",
    "        paras = html.xpath('//*[@id=\"mw-content-text\"]/div[1]/p|//*[@id=\"mw-content-text\"]/div[1]/ul')\n",
    "        link = first_anchor(paras, url)\n",
    "    except: # apparently, no para exists\n",
    "        link = None\n",
    "    return link\n",
    "    \n",
    "def get_first_link(): \n",
    "    'Return link from first random page in wiki format.'\n",
    "    response = requests.get('https://en.wikipedia.org/wiki/Special:Random')\n",
    "    return re.sub('https://en.wikipedia.org', '', response.url)\n",
    "\n",
    "def play(url = None, maxiter = 1000):\n",
    "    # start page\n",
    "    if url is None: \n",
    "        url = get_first_link()\n",
    "    pages = [url]\n",
    "    \n",
    "    exitcode = None\n",
    "    for i in range(0, maxiter): \n",
    "        time.sleep(0.05)\n",
    "        # get next link\n",
    "        link = get_link(url)\n",
    "        # no links to a page\n",
    "        if link is None:  \n",
    "            exitcode = 'deadend'\n",
    "            break\n",
    "        # loop \n",
    "        if pages.count(link) > 0: \n",
    "            exitcode = 'loop'\n",
    "            break \n",
    "        if link == '/wiki/Philosophy':\n",
    "            pages.append(link)\n",
    "            exitcode = 'philosophy'\n",
    "            break \n",
    "        url = link\n",
    "        pages.append(url)\n",
    "        \n",
    "    if exitcode is None: \n",
    "        exitcode = 'maxiter'\n",
    "\n",
    "    return {'pages': pages, 'exitcode': exitcode}\n",
    "\n",
    "def sim(nsim = 200): \n",
    "    'Plays the game nsim times. '\n",
    "    allpages = []\n",
    "    lengths = [None] * nsim\n",
    "    exitcodes = [None] * nsim\n",
    "    for i in range(0, nsim): \n",
    "        result = play()\n",
    "        allpages.extend(result['pages'])\n",
    "        lengths[i] = len(result['pages'])\n",
    "        exitcodes[i] = result['exitcode']\n",
    "    return [allpages, lengths, exitcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/wiki/Robert_Henricks',\n",
       "  '/wiki/Theologian',\n",
       "  '/wiki/Divinity',\n",
       "  '/wiki/Deity',\n",
       "  '/wiki/Supernatural',\n",
       "  '/wiki/Scientific_law',\n",
       "  '/wiki/Reproducibility',\n",
       "  '/wiki/Scientific_method',\n",
       "  '/wiki/Empirical_evidence',\n",
       "  '/wiki/Proposition',\n",
       "  '/wiki/Philosophy_of_language',\n",
       "  '/wiki/Analytic_philosophy',\n",
       "  '/wiki/Philosophy'],\n",
       " [13],\n",
       " ['philosophy']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(1) # takes ~ 20 min, use sim(1) for a single result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mresult\u001b[49m[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "print(pd.Series(result[1]).mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(result[1]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "philosophy    186\n",
       "loop           13\n",
       "deadend         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(result[2]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/wiki/Philosophy                186\n",
       "/wiki/Outline_of_philosophy     167\n",
       "/wiki/Epistemology              167\n",
       "/wiki/Descriptive_knowledge     167\n",
       "/wiki/Knowledge                 167\n",
       "/wiki/Academic_discipline       143\n",
       "/wiki/Analytic_philosophy       142\n",
       "/wiki/Philosophy_of_language    142\n",
       "/wiki/Proposition               142\n",
       "/wiki/Empirical_evidence        142\n",
       "/wiki/Scientific_method         139\n",
       "/wiki/Science                   135\n",
       "/wiki/Branches_of_science        59\n",
       "/wiki/Psychology                 42\n",
       "/wiki/Politics                   31\n",
       "/wiki/Decision-making            31\n",
       "/wiki/Social_science             31\n",
       "/wiki/Physics                    28\n",
       "/wiki/Natural_science            28\n",
       "/wiki/Social_group               26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(result[0]).value_counts().head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
